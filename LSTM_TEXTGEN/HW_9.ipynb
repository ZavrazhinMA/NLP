{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744e827e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T08:13:58.789901Z",
     "start_time": "2021-08-27T08:13:58.783902Z"
    }
   },
   "source": [
    "# Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99a33094",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:09:15.310571Z",
     "start_time": "2021-08-27T19:09:12.780781Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53bfc38",
   "metadata": {},
   "source": [
    "*******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1728dc8",
   "metadata": {},
   "source": [
    "# LOAD data. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57f154b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:09:15.326557Z",
     "start_time": "2021-08-27T19:09:15.312551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1242284 characters\n"
     ]
    }
   ],
   "source": [
    "path_to_file1 = 'af.txt'\n",
    "text = open(path_to_file1, 'rb').read().decode(encoding='utf-8')\n",
    "text = text + text\n",
    "print('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f623228b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:09:15.342551Z",
     "start_time": "2021-08-27T19:09:15.328561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вкус пищи знает тот, кто ест; ответить может лишь тот, кого спрашивают; сны видит лишь тот, кто спит; а для злодея наилучшим примером служит судья, сам достойный суда.\n",
      "\n",
      "Вспыльчивый никогда не познает истину.\n"
     ]
    }
   ],
   "source": [
    "print(text[:207])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eef7fe13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:09:15.438554Z",
     "start_time": "2021-08-27T19:09:15.344553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 unique characters\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14ce62cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:09:15.740549Z",
     "start_time": "2021-08-27T19:09:15.440552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 53,  91, 100, ...,   0,   0,   0]), 1242284, 1242284)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "text_as_int, len(text_as_int), len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ba9cbb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:09:16.514570Z",
     "start_time": "2021-08-27T19:09:15.741551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В\n",
      "к\n",
      "у\n",
      "с\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence you want for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54dda502",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:09:16.546555Z",
     "start_time": "2021-08-27T19:09:16.516551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Вкус пищи знает тот, кто ест; ответить может лишь тот, кого спрашивают; сны видит лишь тот, кто спит;'\n",
      "' а для злодея наилучшим примером служит судья, сам достойный суда.\\n\\nВспыльчивый никогда не познает ис'\n",
      "'тину.\\n\\nДаже разум глупца мирится с истиной.\\n\\nДобро хорошо тогда, когда это истинное добро.\\n\\nЕсли не и'\n",
      "'справишь зло, оно удвоится.\\n\\nЖадность бездонна — в эту пропасть можно падать бесконечно.\\n\\nИстинно вел'\n",
      "'икий не может быть жадным.\\n\\nКривыми путями не добраться барке до гавани.\\n\\nЛишь тот, кто честен и добр'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "130c0c9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:09:16.610571Z",
     "start_time": "2021-08-27T19:09:16.548551Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bb08cbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:09:16.656553Z",
     "start_time": "2021-08-27T19:09:16.611551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'Вкус пищи знает тот, кто ест; ответить может лишь тот, кого спрашивают; сны видит лишь тот, кто спит'\n",
      "Target data: 'кус пищи знает тот, кто ест; ответить может лишь тот, кого спрашивают; сны видит лишь тот, кто спит;'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a236a05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:09:16.672551Z",
     "start_time": "2021-08-27T19:09:16.658553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "embedding_dim = 128\n",
    "rnn_units = 1024\n",
    "vocab_size=len(vocab)\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d1cf72",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fbd70ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:09:16.688551Z",
     "start_time": "2021-08-27T19:09:16.674553Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "                                 \n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "\n",
    "         tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        \n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "                                   \n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a4f53fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:09:17.904570Z",
     "start_time": "2021-08-27T19:09:16.690551Z"
    }
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c78c3d00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:09:17.920552Z",
     "start_time": "2021-08-27T19:09:17.906555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 128)           14976     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 1024)          4722688   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (64, None, 1024)          8392704   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (64, None, 1024)          8392704   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (64, None, 1024)          8392704   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 117)           119925    \n",
      "=================================================================\n",
      "Total params: 30,035,701\n",
      "Trainable params: 30,035,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "495e11fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:09:20.491550Z",
     "start_time": "2021-08-27T19:09:17.922552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 117) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88c4313c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:09:20.507563Z",
     "start_time": "2021-08-27T19:09:20.493555Z"
    }
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "727bf45b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:09:20.523570Z",
     "start_time": "2021-08-27T19:09:20.509552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " ' выказывает мелкую душу.\\n\\nЛучшая месть — забвение, оно похоронит врага в прахе его ничтожества.\\n\\nЛуч'\n",
      "Next Char Predictions: \n",
      " 'cёкркууРШФ/vmиО«mФцРоНdгфXЖзIыжмЧва/\\n[ Вdёkё«пнarмюХОzеБАйо71ЭЯр—akбА7Е9ях1дРf7лЦНЧkс-;5ОуПh…ЯпVМп\\nМ'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c0897fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:09:20.539550Z",
     "start_time": "2021-08-27T19:09:20.525553Z"
    }
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_freq=192*5,\n",
    "    mode='max',\n",
    "    monitor='accuracy',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d651939",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:09:20.555552Z",
     "start_time": "2021-08-27T19:09:20.541552Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "opt = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1003b94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:09:20.587550Z",
     "start_time": "2021-08-27T19:09:20.557553Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, loss=loss, metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5d2030",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b525b1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T19:09:20.602553Z",
     "start_time": "2021-08-27T19:09:20.589551Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fc6b4b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T22:41:51.115720Z",
     "start_time": "2021-08-27T19:09:20.604551Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147bd812",
   "metadata": {},
   "source": [
    "# Text gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "537ee581",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T22:41:52.144827Z",
     "start_time": "2021-08-27T22:41:51.118702Z"
    }
   },
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "029585ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T06:57:32.899368Z",
     "start_time": "2021-08-28T06:57:32.890216Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Number of characters to generate\n",
    "    num_generate = 500\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperature results in more predictable text.\n",
    "    # Higher temperature results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 0.85\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        # Pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10f8e972",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T06:58:40.982629Z",
     "start_time": "2021-08-28T06:58:33.535619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Не для моих знания своих возможности имельшем домачно оказывается вредна. Напротив того, правда в общем. А — боже вас сохрани — не читайте до обеда советских газет. Пациенты, не читающие газет, чувствуют себя природу.\n",
      "\n",
      "Никакое право и великая обязанность свою в отношении настоящего времени, кто наиболее современный человек не принадлежит двум типам людей: человек рисует свой собственный порядок. Так же облудайте опасно, лучший из миров.\n",
      "\n",
      "Наука связывает наслаждение, как наслаждение творить.\n",
      "\n",
      "Есть е\n"
     ]
    }
   ],
   "source": [
    "text_ = generate_text(model, start_string=u\"Не \")\n",
    "print(text_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
